{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8vdkPwZjp8q",
        "outputId": "67d95847-c552-42d1-c2a7-a49156dd846d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-09 21:21:17--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-06-09 21:21:17 (106 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the text file\n",
        "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(f\"Length of dataset in characters: {len(text)}\")\n",
        "print(text[:500])  # Preview the first 500 characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFwdgCxdj5aL",
        "outputId": "0f45bc9d-7370-491d-815c-0f3cd5e6a41e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of dataset in characters: 1115394\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_chars = sorted(set(text))\n",
        "indexes = list(range(len(unique_chars)))\n",
        "char_to_int = dict(zip(unique_chars, indexes))\n",
        "int_to_char = dict(zip(indexes, unique_chars))"
      ],
      "metadata": {
        "id": "wwO5XhvYj7Vz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(x):\n",
        "  return [char_to_int[c] for c in x]\n",
        "\n",
        "def decode(x):\n",
        "  return ''.join([int_to_char[i] for i in x])"
      ],
      "metadata": {
        "id": "JL1sZcfBj8vG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = encode(text)\n",
        "split_idx = int(len(encoded_text) * 0.9)\n",
        "train_text = encoded_text[:split_idx]\n",
        "val_text = encoded_text[split_idx:]"
      ],
      "metadata": {
        "id": "cVu0RGuQj93W"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 64\n",
        "def create_sequences(data, block_size):\n",
        "    inputs = []\n",
        "    targets = []\n",
        "\n",
        "    for i in range(len(data) - block_size):\n",
        "        input_seq = data[i:i + block_size]\n",
        "        target_seq = data[i + 1:i + block_size + 1]\n",
        "\n",
        "        inputs.append(input_seq)\n",
        "        targets.append(target_seq)\n",
        "\n",
        "    return inputs, targets\n",
        "train_inputs, train_targets = create_sequences(train_text, block_size)\n",
        "val_inputs, val_targets = create_sequences(val_text, block_size)\n"
      ],
      "metadata": {
        "id": "cCCn-ilkj_Rw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_batch(inputs, targets, batch_size):\n",
        "    assert len(inputs) == len(targets)\n",
        "    indices = random.sample(range(len(inputs)), batch_size)\n",
        "    input_batch = np.array([inputs[i] for i in indices], dtype=np.int32)\n",
        "    target_batch = np.array([targets[i] for i in indices], dtype=np.int32)\n",
        "    return input_batch, target_batch"
      ],
      "metadata": {
        "id": "s_8cf4HAkA8b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "vocab_size = 65\n",
        "embedding_dim = 128\n",
        "\n",
        "embedding_matrix = np.random.randn(vocab_size, embedding_dim) * 0.01\n",
        "\n",
        "def embedded_input(input_ids):\n",
        "    return embedding_matrix[input_ids] + positional_embedding[np.arange(input_ids.shape[1])]\n",
        "\n",
        "positional_embedding = np.random.randn(block_size, embedding_dim) * 0.01"
      ],
      "metadata": {
        "id": "FsGZdeE5kCWj"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}